{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44db416f",
   "metadata": {},
   "source": [
    "# üìö Project Brief ‚Äì Books to Scrape\n",
    "\n",
    "## ‚è±Ô∏è Estimated Time : **300 minutes (5 hours)**\n",
    "\n",
    "\n",
    "This project will guide you through building a **web scraper** for the site [Books to Scrape](https://books.toscrape.com/). It is designed as a hands-on exercise to practice **Python, requests, Pandas, and data analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bc308",
   "metadata": {},
   "source": [
    "## üéØ Context\n",
    "\n",
    "The marketing team of a online bookstore wants to better understand their catalog. They want to collect information about all books, analyze categories, prices, ratings, and stock availability.\n",
    "\n",
    "As a data scientist, your mission is to **scrape the website** and deliver structured datasets and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac0626",
   "metadata": {},
   "source": [
    "## ‚úÖ Goals\n",
    "\n",
    "1. Scrape the website [Books to Scrape](https://books.toscrape.com/)\n",
    "2. Extract for each book:\n",
    "   - Title\n",
    "   - Price\n",
    "   - Stock availability\n",
    "   - Rating\n",
    "   - Product URL\n",
    "   - Image URL\n",
    "   - UPC\n",
    "   - Category\n",
    "3. Handle **pagination** across all pages\n",
    "4. Save results into **one CSV per category**\n",
    "5. Download book cover images into folders per category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c460d7",
   "metadata": {},
   "source": [
    "## üì¶ Deliverables\n",
    "\n",
    "- CSV files: `outputs/csv/category_<slug>.csv`\n",
    "- Images: `outputs/images/<category>/<upc>_<slug-title>.jpg`\n",
    "- Optional: A summary notebook that cleans the data and explores prices, ratings, and stock using Pandas and your best vizualisation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571b150",
   "metadata": {},
   "source": [
    "## üí° Hints\n",
    "\n",
    "- Use the libraries: `requests`, `scrapy`, and `lxml`\n",
    "- Inspect the HTML with your browser (right-click ‚Üí *Inspect*) to identify selectors\n",
    "- Ratings are given as words in the `class` attribute (e.g., `star-rating Three`)\n",
    "- Use helper functions to keep your code clean (e.g., `parse_book()`, `parse_category()`)\n",
    "- Add delays between requests (`time.sleep`) to avoid hammering the server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fdee8a",
   "metadata": {},
   "source": [
    "## üõ† Suggested Steps\n",
    "\n",
    "1. Start by scraping **one book page** and extract the required fields\n",
    "2. Extend your code to **one category** (handle multiple pages)\n",
    "3. Generalize your scraper to cover **all categories**\n",
    "4. Save the results into CSV files\n",
    "5. Extend your scraper to also **download images**\n",
    "6. (Optional) Explore the dataset with Pandas (average price per category, distribution of ratings, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a80dc",
   "metadata": {},
   "source": [
    "## üìù Evaluation Criteria\n",
    "\n",
    "- Correctness of the scraper (all required fields extracted)\n",
    "- Clean code structure (functions, reusable logic)\n",
    "- Proper CSV and image outputs\n",
    "- (Optional) Extra credit for insightful visualizations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
